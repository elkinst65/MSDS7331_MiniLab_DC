{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS 7331 - Mini Lab: Logistic Regression and SVMs\n",
    "\n",
    "### Investigators\n",
    "- [Matt Baldree](mailto:mbaldree@smu.edu?subject=lab1)\n",
    "- [Tom Elkins](telkins@smu.edu?subject=lab1)\n",
    "- [Austin Kelly](ajkelly@smu.edu?subject=lab1)\n",
    "- [Murali Parthasarathy](mparthasarathy@smu.edu?subject=lab1)\n",
    "\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:5px;'>\n",
    "    <h3>Lab Instructions</h3>\n",
    "    <p>You are to perform predictive analysis (classification) upon a data set: model the dataset using methods we have discussed in class: logistic regression and support vector machines, and making conclusions from the analysis. Follow the CRISP-DM framework in your analysis (you are not performing all of the CRISP-DM outline, only the portions relevant to the grading rubric outlined below). This report is worth 10% of the final grade. You may complete this assignment in teams of as many as three people.\n",
    "Write a report covering all the steps of the project. The format of the document can be PDF, *.ipynb, or HTML. You can write the report in whatever format you like, but it is easiest to turn in the rendered iPython notebook. The results should be reproducible using your report. Please carefully describe every assumption and every step in your report.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_prep'></a>\n",
    "## 1 - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36489 entries, 0 to 36488\n",
      "Data columns (total 27 columns):\n",
      "REPORT_DATE             36489 non-null datetime64[ns]\n",
      "SHIFT                   36489 non-null object\n",
      "OFFENSE                 36489 non-null object\n",
      "METHOD                  36489 non-null object\n",
      "DISTRICT                36442 non-null float64\n",
      "PSA                     36441 non-null float64\n",
      "WARD                    36489 non-null int64\n",
      "ANC                     36489 non-null int64\n",
      "NEIGHBORHOOD_CLUSTER    36489 non-null int64\n",
      "CENSUS_TRACT            36489 non-null int64\n",
      "VOTING_PRECINCT         36489 non-null int64\n",
      "CCN                     36489 non-null int64\n",
      "XBLOCK                  36489 non-null float64\n",
      "YBLOCK                  36489 non-null float64\n",
      "START_DATE              36489 non-null datetime64[ns]\n",
      "END_DATE                36489 non-null datetime64[ns]\n",
      "PSA_ID                  36489 non-null int64\n",
      "DistrictID              36489 non-null int64\n",
      "SHIFT_Code              36489 non-null int64\n",
      "OFFENSE_Code            36489 non-null int64\n",
      "METHOD_Code             36489 non-null int64\n",
      "CRIME_TYPE              36489 non-null int64\n",
      "AGE                     36489 non-null int64\n",
      "TIME_TO_REPORT          36489 non-null int64\n",
      "Latitude                36489 non-null float64\n",
      "Longitude               36489 non-null float64\n",
      "Crime_Month             36489 non-null int64\n",
      "dtypes: datetime64[ns](3), float64(6), int64(15), object(3)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#1.0.1 - Import the libraries we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2)\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True) # one of the many color mappings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Read in the crime data from the Lab 1 CSV file\n",
    "dc = pd.read_csv('data/DC_Crime_2015_Lab1.csv')\n",
    "\n",
    "### *** TO DO:\n",
    "###  * Incorporate a feature for the weather conditions during START_DATE and END_DATE so we can use rainfall/max temp/min temp in the regression\n",
    "dc['REPORT_DAT'] = pd.to_datetime(dc['REPORT_DAT'])\n",
    "dc=dc.rename(columns = {'REPORT_DAT':'REPORT_DATE'})\n",
    "dc['START_DATE'] = pd.to_datetime(dc['START_DATE'])\n",
    "dc['END_DATE'] = pd.to_datetime(dc['END_DATE'])\n",
    "dc['XBLOCK'] = dc['XBLOCK'].astype(np.float64)\n",
    "dc['YBLOCK'] = dc['YBLOCK'].astype(np.float64)\n",
    "dc['Crime_Month'] = dc[\"START_DATE\"].map(lambda x: x.month)\n",
    "dc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Dataset Review\n",
    "We continue to use our dataset selected for lab 1 - the 2015 Washington, D.C. Metro Crime data.  That dataset contained the type of crime committed (Field name \"OFFENSE\"; from which we derived an \"Offense_Code\" field and ascribed a numeric value for each offense type (NOTE: The number used does not imply a level of severity they were simply applied in order of appearance).  :\n",
    "\n",
    "|Offense|Offense_Code|Crime_Type|\n",
    "|:------|:----------:|---------:|\n",
    "|Theft/Other|1|2 (Property)|\n",
    "|Theft from Auto|2|2 (Property)|\n",
    "|Burglary|3|2 (Property)|\n",
    "|Assault with Dangerous Weapon|4|1 (Violent)|\n",
    "|Robbery|5|1 (Violent)|\n",
    "|Motor Vehicle Theft|6|2 (Property)|\n",
    "|Homicide|7|1 (Violent)|\n",
    "|Sex Abuse|8|1 (Violent)|\n",
    "|Arson|9|2 (Property)|\n",
    "\n",
    "The dataset contains a variety of geographic identifiers representing different political, social, and legal boundaries.\n",
    "\n",
    "DISTRICT -- the Police district within which the crime was committed<br>\n",
    "Police Service Area (PSA) -- A subordinate area within a District<br>\n",
    "Ward -- A political area, similar to a \"county\" in a larger state<br>\n",
    "Advisory Neighborhood Committed (ANC) -- A social group consisting of neighbors and social leaders in a small geographic area<br>\n",
    "Voting Precinct -- A political area for the management of voting residents<br>\n",
    "Local Coordinates (XBLOCK and YBLOCK) -- location within the DC metro area based on the Maryland mapping system<br>\n",
    "Global Coordinates (Latitude and Longitude) -- location on the planet<br>\n",
    "\n",
    "There are also time-based identifiers provided in the data\n",
    "* The Start and End dates/times of when the crime *might* have been committed.\n",
    "* The date/time the crime was reported (i.e. when the police responded and took the report)\n",
    "* These can be further decomposed to Seasons, Months, Weeks, Day of the Week, etc.\n",
    "* Shift - the police duty shift that responded to the crime (broken into 8-hour periods within a day)\n",
    "\n",
    "From these time-based data we could associate environmental conditions as well, including temperatures, rainfall, phase of the moon, etc.\n",
    "\n",
    "These features give us a variety of ways to attempt to classify the data.\n",
    "\n",
    "### 1.2 - Classification Tasks\n",
    "We decided to take a look at two different classification processes with our data set.\n",
    "\n",
    "#### 1.2.1 - Crime_Type (Violent/Property)\n",
    "The second classification task is a binary classification, in which we attempt to build a model to predict whether the crime will be against a person (violent) or against property. Again, the goal is to help the Police manage resources more appropriately.\n",
    "\n",
    "#### 1.2.2 - Offense/Offense_Code\n",
    "For the first classification task, we chose to attempt building a model to predict the type of offense given the other features of the data (geographic location, time of day, political area, etc.).  The hope is that if a type of crime could be predicted, then the Police would be better able to allocate offense-specific resources appropriately.\n",
    "\n",
    "#### 1.2.3 - Model Comparison\n",
    "Secondarily, we seek to compare the accuracy of the models - i.e. if the Crime_Type prediction indicates a \"Violent\" crime, does the Offense prediction agree (Homicide, Sex Abuse, Robbery, or Assault).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model_building\"></a>\n",
    "## 2 - Model Building\n",
    "\n",
    "<div style='margin-left:10%;margin-right:10%;margin-top:15px;background-color:#d3d3d3;padding:10px;'>\n",
    "<h3>SVM and Logistic Regression Modeling</h3>\n",
    "    <ol><li>[<b>50 points</b>] Create a logistic regression model and a support vector machine model for the classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use.</li>\n",
    "    <li>[<b>10 points</b>]  Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail.</li>\n",
    "    <li>[<b>30 points</b>] Use the weights from logistic regression to interpret the importance of different features for each classification task. Explain your interpretation in detail. Why do you think some variables are more important?</li>\n",
    "    <li>[<b>10 points</b>]  Look at the chosen support vectors for the classification task. Do these provide\n",
    "any insight into the data? Explain.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Logistic Regression Model for Crime_Type (Rubric Item 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean response for the entire data set is 0.169174271698\n",
      "If we simply guessed 'Property' crime all the time, our accuracy would be 0.830825728302\n",
      "Accuracy of Logistic Regression model is 0.830250212393\n",
      "The Logistic Regression model is worse than simply guessing\n"
     ]
    }
   ],
   "source": [
    "#2.1.1 Dataset creation\n",
    "\n",
    "#  The field \"CRIME_TYPE\" exists as 1 = Violent, and 2 = Property.  \n",
    "#  We subtract from 2 to make it 1 = Violent, and 0 = Property\n",
    "LRM_Response = 2 - dc[\"CRIME_TYPE\"]\n",
    "#print LRM_Response\n",
    "\n",
    "#  What is the mean response\n",
    "Mean_Response = LRM_Response.mean()\n",
    "print \"Mean response for the entire data set is \" + str(Mean_Response)\n",
    "\n",
    "Guess_Rate = 1.0 - Mean_Response\n",
    "print \"If we simply guessed 'Property' crime all the time, our accuracy would be \" + str(Guess_Rate)\n",
    "\n",
    "#  Set up model using all relevant features\n",
    "LRM_Features = dc[[\"PSA_ID\",\"WARD\",\"ANC\",\"NEIGHBORHOOD_CLUSTER\",\"CENSUS_TRACT\",\"VOTING_PRECINCT\",\"SHIFT_Code\",\"Latitude\",\"Longitude\",\"Crime_Month\"]]\n",
    "#print LRM_Features\n",
    "\n",
    "#  Fit our model\n",
    "LRM_Model = LogisticRegression()\n",
    "LRM_Model = LRM_Model.fit(LRM_Features, LRM_Response)\n",
    "\n",
    "#  How accurate is it?\n",
    "Model_Acc = LRM_Model.score(LRM_Features, LRM_Response)\n",
    "print \"Accuracy of Logistic Regression model is \" + str(Model_Acc)\n",
    "\n",
    "if Model_Acc > Guess_Rate:\n",
    "    print \"The Logistic Regression model is better than simply guessing\"\n",
    "else:\n",
    "    print \"The Logistic Regression model is worse than simply guessing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PSA_ID</td>\n",
       "      <td>[0.00167783221638]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WARD</td>\n",
       "      <td>[0.0195928056189]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANC</td>\n",
       "      <td>[0.00886350684632]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEIGHBORHOOD_CLUSTER</td>\n",
       "      <td>[-0.00232184509213]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CENSUS_TRACT</td>\n",
       "      <td>[-1.37492426304e-05]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VOTING_PRECINCT</td>\n",
       "      <td>[0.0014077633811]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SHIFT_Code</td>\n",
       "      <td>[0.79779478674]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>[-0.0193099343437]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>[0.0475113614735]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Crime_Month</td>\n",
       "      <td>[0.00955306118479]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                     1\n",
       "0                PSA_ID    [0.00167783221638]\n",
       "1                  WARD     [0.0195928056189]\n",
       "2                   ANC    [0.00886350684632]\n",
       "3  NEIGHBORHOOD_CLUSTER   [-0.00232184509213]\n",
       "4          CENSUS_TRACT  [-1.37492426304e-05]\n",
       "5       VOTING_PRECINCT     [0.0014077633811]\n",
       "6            SHIFT_Code       [0.79779478674]\n",
       "7              Latitude    [-0.0193099343437]\n",
       "8             Longitude     [0.0475113614735]\n",
       "9           Crime_Month    [0.00955306118479]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Display the coefficients to see if they tell us anything\n",
    "pd.DataFrame(zip(LRM_Features.columns, np.transpose(LRM_Model.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The most significant factor is the SHIFT (i.e. the time of day)\n",
    "* The second-most significant factor is Longitude, implying that as you move east, your chances of being involved in a violent crime increases\n",
    "* The third-most significant factor is political WARD, so there are some Wards that are worse than others\n",
    "* The fourth-most significant factor is Latitude, but negatively, so there is a greater chance of being involved in a violent crime as you move south"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model is 0.830250212393\n",
      "The Logistic Regression model is worse than simply guessing\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training set and a test set (80/20)\n",
    "\n",
    "LRM_XTrain, LRM_XTest, LRM_YTrain, LRM_YTest = train_test_split(LRM_Features, LRM_Response, test_size=0.2, random_state=0)\n",
    "\n",
    "# Fit the same features against the training data\n",
    "LRM_Model2 = LogisticRegression()\n",
    "LRM_Model2.fit(LRM_XTrain, LRM_YTrain)\n",
    "\n",
    "#  How accurate is it?\n",
    "Model_Acc = LRM_Model2.score(LRM_Features, LRM_Response)\n",
    "print \"Accuracy of Logistic Regression model is \" + str(Model_Acc)\n",
    "\n",
    "if Model_Acc > Guess_Rate:\n",
    "    print \"The Logistic Regression model is better than simply guessing\"\n",
    "else:\n",
    "    print \"The Logistic Regression model is worse than simply guessing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n",
      "[[ 0.62327851  0.37672149]\n",
      " [ 0.86575354  0.13424646]\n",
      " [ 0.91667427  0.08332573]\n",
      " ..., \n",
      " [ 0.8726165   0.1273835 ]\n",
      " [ 0.84396971  0.15603029]\n",
      " [ 0.86138094  0.13861906]]\n",
      "0.825020553576\n",
      "0.720589616457\n",
      "[[5919   82]\n",
      " [1195  102]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.99      0.90      6001\n",
      "          1       0.55      0.08      0.14      1297\n",
      "\n",
      "avg / total       0.78      0.83      0.77      7298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = LRM_Model2.predict(LRM_XTest)\n",
    "print predicted\n",
    "\n",
    "# generate class probabilities\n",
    "probs = LRM_Model2.predict_proba(LRM_XTest)\n",
    "print probs\n",
    "\n",
    "# generate evaluation metrics\n",
    "print metrics.accuracy_score(LRM_YTest, predicted)\n",
    "print metrics.roc_auc_score(LRM_YTest, probs[:, 1])\n",
    "\n",
    "print metrics.confusion_matrix(LRM_YTest, predicted)\n",
    "print metrics.classification_report(LRM_YTest, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83068493  0.83068493  0.83068493  0.83091258  0.83091258  0.83063853\n",
      "  0.83086623  0.83004386  0.81030702  0.73574561]\n",
      "0.81914812025\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), LRM_Features,LRM_Response, scoring='accuracy', cv=10)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Support Vector Machine Model for Crime_Type (Rubric Item 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Logistic Regression Model for Offense_Code (Exceptional Work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Support Vector Machine Model for Offense_Code (Exceptional Work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Advantages of Each Model (Rubric Item 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 - Logistic Regression Weights (Rubric Item 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 - Support Vectors (Rubric Item 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
